{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "581b1971cef54882846fd0bc6001b4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c0000bed124f3d8f4de49ac9a5d1a9",
              "IPY_MODEL_851396d3bc0e4a0093cb180e588a0291",
              "IPY_MODEL_8f45f21e87b24c218687881ec708fda2"
            ],
            "layout": "IPY_MODEL_6ea858c2aa474ea2822771f9f233200d"
          }
        },
        "a0c0000bed124f3d8f4de49ac9a5d1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78beeccce835436aad268f99e054e14b",
            "placeholder": "​",
            "style": "IPY_MODEL_640bbbfec2bb458a9410fee1a9506b2c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "851396d3bc0e4a0093cb180e588a0291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7b840c212549c6b5468eb8f5df1bcb",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_501f7ce76355430aa4138a9565fd9cb4",
            "value": 49
          }
        },
        "8f45f21e87b24c218687881ec708fda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3876954ff77446fc87eee2c2e1afbc12",
            "placeholder": "​",
            "style": "IPY_MODEL_a95fa219839645809cf7b32022bdcb38",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "6ea858c2aa474ea2822771f9f233200d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78beeccce835436aad268f99e054e14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640bbbfec2bb458a9410fee1a9506b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7b840c212549c6b5468eb8f5df1bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501f7ce76355430aa4138a9565fd9cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3876954ff77446fc87eee2c2e1afbc12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95fa219839645809cf7b32022bdcb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dced6328bf147bda91cea94ba16a671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94aa216a774a467ba75f7de42060c05c",
              "IPY_MODEL_0d2571b872ec4273aa7a16ebbeb9b22c",
              "IPY_MODEL_f133b9efb0c64ba7b16eaa519a023da8"
            ],
            "layout": "IPY_MODEL_9460b24279864469a95737782a8c64aa"
          }
        },
        "94aa216a774a467ba75f7de42060c05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f423b85fda4f97bf07754c97a18a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_e172f66792174e50a388b3745f0c01b1",
            "value": "config.json: 100%"
          }
        },
        "0d2571b872ec4273aa7a16ebbeb9b22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041a7bc42dd4462aaeab3836a35bf7a2",
            "max": 462,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f6ae68dcf834eb18c21e82de1aec43a",
            "value": 462
          }
        },
        "f133b9efb0c64ba7b16eaa519a023da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a14da8e9b39448a93f8e7317293da28",
            "placeholder": "​",
            "style": "IPY_MODEL_8457e548c52f4fc3bbfcd95c3f0b9013",
            "value": " 462/462 [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "9460b24279864469a95737782a8c64aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f423b85fda4f97bf07754c97a18a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e172f66792174e50a388b3745f0c01b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041a7bc42dd4462aaeab3836a35bf7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6ae68dcf834eb18c21e82de1aec43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a14da8e9b39448a93f8e7317293da28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8457e548c52f4fc3bbfcd95c3f0b9013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2933e3aa0c4eaeaa06cf669b1a457d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b20c516de664d1490c144e41b255469",
              "IPY_MODEL_8e786fd434c74d44ba86d497ac87652b",
              "IPY_MODEL_c88da19c4acf4dbaad6cbdc3beebaef1"
            ],
            "layout": "IPY_MODEL_1b432c0824794c4fb69a6bcc6e46261f"
          }
        },
        "0b20c516de664d1490c144e41b255469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a1e45f255340b3b2a00764349c7a2b",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2146c519714feeb325eed8fc0dda96",
            "value": "vocab.txt: 100%"
          }
        },
        "8e786fd434c74d44ba86d497ac87652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25657af99d0c4ddca73a78bb2a967b52",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5c1d62dd75a4787bd44e385f1a5dca4",
            "value": 213450
          }
        },
        "c88da19c4acf4dbaad6cbdc3beebaef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3485a33d8a4024a6c30ebfc4ae2b04",
            "placeholder": "​",
            "style": "IPY_MODEL_d99f8696ec0449a5bcf7405106856f7d",
            "value": " 213k/213k [00:00&lt;00:00, 1.29MB/s]"
          }
        },
        "1b432c0824794c4fb69a6bcc6e46261f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a1e45f255340b3b2a00764349c7a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2146c519714feeb325eed8fc0dda96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25657af99d0c4ddca73a78bb2a967b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c1d62dd75a4787bd44e385f1a5dca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3485a33d8a4024a6c30ebfc4ae2b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99f8696ec0449a5bcf7405106856f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffd6d2894e0d42b4a9e2da041b05b5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcac1fb7bc5c4651865e9bb6bb6c7161",
              "IPY_MODEL_0f3b2edea3b64be09175cc084eca40bd",
              "IPY_MODEL_3e71c28f9c794584a65f928a2c735ba1"
            ],
            "layout": "IPY_MODEL_2f7cc1d8a177448fa86e50ad33128793"
          }
        },
        "dcac1fb7bc5c4651865e9bb6bb6c7161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd23b4da90f45beb4c69b39ccf56e4e",
            "placeholder": "​",
            "style": "IPY_MODEL_42237c9a589346e69820abdf31411c83",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0f3b2edea3b64be09175cc084eca40bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566c232f94f149479fd2a600dd3c8257",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f871a790d45344f7b975ded4578c98de",
            "value": 112
          }
        },
        "3e71c28f9c794584a65f928a2c735ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b96fa3491d244a3b5bd195113f65366",
            "placeholder": "​",
            "style": "IPY_MODEL_1bdacfc4799c46d79b6ba22e3fde8ada",
            "value": " 112/112 [00:00&lt;00:00, 6.57kB/s]"
          }
        },
        "2f7cc1d8a177448fa86e50ad33128793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd23b4da90f45beb4c69b39ccf56e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42237c9a589346e69820abdf31411c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566c232f94f149479fd2a600dd3c8257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f871a790d45344f7b975ded4578c98de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b96fa3491d244a3b5bd195113f65366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bdacfc4799c46d79b6ba22e3fde8ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3511d0959ab64be0b5a36e5461289b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_584882b4d5f943e2a1cdfc712889a839",
              "IPY_MODEL_0d131a79cd704d74b04b671cba1c1e1b",
              "IPY_MODEL_ef7bb9c96fa143819da5f599b2cef3ef"
            ],
            "layout": "IPY_MODEL_5f28d4727fbc44f79474839031647756"
          }
        },
        "584882b4d5f943e2a1cdfc712889a839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a163482e64425a8121e97ef23629de",
            "placeholder": "​",
            "style": "IPY_MODEL_8b7ccddacd7d4e28b02b78135a872429",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0d131a79cd704d74b04b671cba1c1e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d514daef08374572bf98763e8ee12128",
            "max": 433286112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d3078aa0a32476d822f2bfd2feca7e3",
            "value": 433286112
          }
        },
        "ef7bb9c96fa143819da5f599b2cef3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8799ef6c03284c219c65a91d857edc90",
            "placeholder": "​",
            "style": "IPY_MODEL_be758f3772374ac29c1150574e6792b6",
            "value": " 433M/433M [00:01&lt;00:00, 251MB/s]"
          }
        },
        "5f28d4727fbc44f79474839031647756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a163482e64425a8121e97ef23629de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7ccddacd7d4e28b02b78135a872429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d514daef08374572bf98763e8ee12128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3078aa0a32476d822f2bfd2feca7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8799ef6c03284c219c65a91d857edc90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be758f3772374ac29c1150574e6792b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Retrieval part"
      ],
      "metadata": {
        "id": "WVMSU8HxsdGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb openai langchain\n",
        "!pip install transformers torch sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K4PPGf8ItHdy",
        "outputId": "20ed74c7-d0ff-4506-f9c4-9b22b94dae8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.18-py3-none-any.whl (615 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.28.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.49b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=81288ebc0ae5cf624f08aa7381af35028986070c8360dc61ee0bf1f51172a693\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.18 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.4 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-api-1.28.0 opentelemetry-exporter-otlp-proto-common-1.28.0 opentelemetry-exporter-otlp-proto-grpc-1.28.0 opentelemetry-instrumentation-0.49b0 opentelemetry-instrumentation-asgi-0.49b0 opentelemetry-instrumentation-fastapi-0.49b0 opentelemetry-proto-1.28.0 opentelemetry-sdk-1.28.0 opentelemetry-semantic-conventions-0.49b0 opentelemetry-util-http-0.49b0 overrides-7.7.0 posthog-3.7.0 protobuf-5.28.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-13.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSLFoAkN3QEt",
        "outputId": "7217d2ad-ff97-4fa9-ba0f-ad21cf921d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import hashlib\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_heart_attack_dataset(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    processed_data = {\n",
        "        'questions': [],\n",
        "        'documents': [],\n",
        "        'snippets': [],\n",
        "        'document_snippets': defaultdict(list),\n",
        "        'question_documents': defaultdict(set)\n",
        "    }\n",
        "\n",
        "    document_set = set()\n",
        "    snippet_set = set()\n",
        "\n",
        "    for item in data['questions']:\n",
        "        question_id = item['id']\n",
        "        question_body = item['body']\n",
        "\n",
        "        processed_data['questions'].append({\n",
        "            'id': question_id,\n",
        "            'body': question_body,\n",
        "            'type': item['type'],\n",
        "            'ideal_answer': item['ideal_answer']\n",
        "        })\n",
        "\n",
        "        # Process documents\n",
        "        for doc in item['documents']:\n",
        "            if doc not in document_set:\n",
        "                document_set.add(doc)\n",
        "                processed_data['documents'].append({\n",
        "                    'id': f\"doc_{len(processed_data['documents'])}\",\n",
        "                    'url': doc\n",
        "                })\n",
        "            processed_data['question_documents'][question_id].add(doc)\n",
        "\n",
        "        # Process snippets\n",
        "        for snippet in item['snippets']:\n",
        "            snippet_text = snippet['text']\n",
        "            snippet_doc = snippet['document']\n",
        "            snippet_hash = hashlib.md5(snippet_text.encode()).hexdigest()\n",
        "\n",
        "            if snippet_hash not in snippet_set:\n",
        "                snippet_set.add(snippet_hash)\n",
        "                snippet_id = f\"snippet_{len(processed_data['snippets'])}\"\n",
        "                processed_data['snippets'].append({\n",
        "                    'id': snippet_id,\n",
        "                    'text': snippet_text,\n",
        "                    'document': snippet_doc,\n",
        "                    'begin_section': snippet['beginSection'],\n",
        "                    'end_section': snippet['endSection'],\n",
        "                    'offset_begin': snippet['offsetInBeginSection'],\n",
        "                    'offset_end': snippet['offsetInEndSection']\n",
        "                })\n",
        "                processed_data['document_snippets'][snippet_doc].append(snippet_id)\n",
        "\n",
        "    # Convert sets to lists for JSON serialization\n",
        "    processed_data['question_documents'] = {k: list(v) for k, v in processed_data['question_documents'].items()}\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "\n",
        "# Load BioBERT model\n",
        "model_name = \"dmis-lab/biobert-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get BioBERT embeddings\n",
        "def get_biobert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "581b1971cef54882846fd0bc6001b4e5",
            "a0c0000bed124f3d8f4de49ac9a5d1a9",
            "851396d3bc0e4a0093cb180e588a0291",
            "8f45f21e87b24c218687881ec708fda2",
            "6ea858c2aa474ea2822771f9f233200d",
            "78beeccce835436aad268f99e054e14b",
            "640bbbfec2bb458a9410fee1a9506b2c",
            "ff7b840c212549c6b5468eb8f5df1bcb",
            "501f7ce76355430aa4138a9565fd9cb4",
            "3876954ff77446fc87eee2c2e1afbc12",
            "a95fa219839645809cf7b32022bdcb38",
            "9dced6328bf147bda91cea94ba16a671",
            "94aa216a774a467ba75f7de42060c05c",
            "0d2571b872ec4273aa7a16ebbeb9b22c",
            "f133b9efb0c64ba7b16eaa519a023da8",
            "9460b24279864469a95737782a8c64aa",
            "e1f423b85fda4f97bf07754c97a18a1a",
            "e172f66792174e50a388b3745f0c01b1",
            "041a7bc42dd4462aaeab3836a35bf7a2",
            "5f6ae68dcf834eb18c21e82de1aec43a",
            "5a14da8e9b39448a93f8e7317293da28",
            "8457e548c52f4fc3bbfcd95c3f0b9013",
            "cc2933e3aa0c4eaeaa06cf669b1a457d",
            "0b20c516de664d1490c144e41b255469",
            "8e786fd434c74d44ba86d497ac87652b",
            "c88da19c4acf4dbaad6cbdc3beebaef1",
            "1b432c0824794c4fb69a6bcc6e46261f",
            "f5a1e45f255340b3b2a00764349c7a2b",
            "2b2146c519714feeb325eed8fc0dda96",
            "25657af99d0c4ddca73a78bb2a967b52",
            "c5c1d62dd75a4787bd44e385f1a5dca4",
            "4a3485a33d8a4024a6c30ebfc4ae2b04",
            "d99f8696ec0449a5bcf7405106856f7d",
            "ffd6d2894e0d42b4a9e2da041b05b5ef",
            "dcac1fb7bc5c4651865e9bb6bb6c7161",
            "0f3b2edea3b64be09175cc084eca40bd",
            "3e71c28f9c794584a65f928a2c735ba1",
            "2f7cc1d8a177448fa86e50ad33128793",
            "acd23b4da90f45beb4c69b39ccf56e4e",
            "42237c9a589346e69820abdf31411c83",
            "566c232f94f149479fd2a600dd3c8257",
            "f871a790d45344f7b975ded4578c98de",
            "9b96fa3491d244a3b5bd195113f65366",
            "1bdacfc4799c46d79b6ba22e3fde8ada",
            "3511d0959ab64be0b5a36e5461289b71",
            "584882b4d5f943e2a1cdfc712889a839",
            "0d131a79cd704d74b04b671cba1c1e1b",
            "ef7bb9c96fa143819da5f599b2cef3ef",
            "5f28d4727fbc44f79474839031647756",
            "32a163482e64425a8121e97ef23629de",
            "8b7ccddacd7d4e28b02b78135a872429",
            "d514daef08374572bf98763e8ee12128",
            "8d3078aa0a32476d822f2bfd2feca7e3",
            "8799ef6c03284c219c65a91d857edc90",
            "be758f3772374ac29c1150574e6792b6"
          ]
        },
        "id": "upj_CRX268GR",
        "outputId": "59ad1e5c-8932-47ee-dc6a-a1525b9afbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "581b1971cef54882846fd0bc6001b4e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dced6328bf147bda91cea94ba16a671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc2933e3aa0c4eaeaa06cf669b1a457d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffd6d2894e0d42b4a9e2da041b05b5ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3511d0959ab64be0b5a36e5461289b71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usage\n",
        "file_path = 'heart_attack_dataset.json'\n",
        "preprocessed_data = preprocess_heart_attack_dataset(file_path)\n",
        "\n",
        "# Initialize Chroma client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Create a collection\n",
        "collection = client.create_collection(name=\"heart_attack_data_biobert\")\n",
        "\n",
        "# Prepare documents and snippets for embedding\n",
        "document_texts = [doc['url'] for doc in preprocessed_data['documents']]\n",
        "snippet_texts = [snippet['text'] for snippet in preprocessed_data['snippets']]\n",
        "all_texts = document_texts + snippet_texts\n",
        "\n",
        "# Get BioBERT embeddings\n",
        "all_embeddings = [get_biobert_embedding(text) for text in all_texts]\n",
        "\n",
        "# Add documents to the collection\n",
        "collection.add(\n",
        "    ids=[doc['id'] for doc in preprocessed_data['documents']],\n",
        "    documents=document_texts,\n",
        "    embeddings=all_embeddings[:len(document_texts)]\n",
        ")\n",
        "\n",
        "# Add snippets to the collection\n",
        "collection.add(\n",
        "    ids=[snippet['id'] for snippet in preprocessed_data['snippets']],\n",
        "    documents=snippet_texts,\n",
        "    embeddings=all_embeddings[len(document_texts):]\n",
        ")\n",
        "\n",
        "print(f\"Added {len(preprocessed_data['documents'])} documents and {len(preprocessed_data['snippets'])} snippets to the Chroma database.\")\n",
        "\n",
        "# Function to query the collection\n",
        "def query_collection(query_text, n_results=3):\n",
        "    query_embedding = get_biobert_embedding(query_text)\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding.tolist()],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    return results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PVs8MkL7PfQ",
        "outputId": "ca0c7be5-ff5a-4e39-f606-a513c9e08288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 100 documents and 143 snippets to the Chroma database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query\n",
        "query = \"What are the symptoms of a heart attack?\"\n",
        "results = query_collection(query)\n",
        "\n",
        "print(\"\\nQuery results:\")\n",
        "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
        "    print(f\"Result {i+1}:\")\n",
        "    print(f\"Document: {doc}\")\n",
        "    print(f\"Distance: {distance}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6DJYabd7fk8",
        "outputId": "f438032f-c9be-40fc-bfe8-32f879148629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query results:\n",
            "Result 1:\n",
            "Document: A heart attack is diagnosed using an ECG, blood tests for cardiac enzymes, and imaging tests like angiography.\n",
            "Distance: 26.08465576171875\n",
            "---\n",
            "Result 2:\n",
            "Document: An ECG detects irregular heart rhythms and damage to heart muscle, which are critical for diagnosing heart attacks.\n",
            "Distance: 27.27193832397461\n",
            "---\n",
            "Result 3:\n",
            "Document: Silent heart attacks show no obvious symptoms but can still cause significant heart damage and increase future heart attack risk.\n",
            "Distance: 27.518798828125\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Generation part"
      ],
      "metadata": {
        "id": "sWPSdGUDkI8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import hashlib\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_heart_attack_dataset(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    processed_data = {\n",
        "        'questions': [],\n",
        "        'documents': [],\n",
        "        'snippets': [],\n",
        "        'document_snippets': defaultdict(list),\n",
        "        'question_documents': defaultdict(set)\n",
        "    }\n",
        "\n",
        "    document_set = set()\n",
        "    snippet_set = set()\n",
        "\n",
        "    for item in data['questions']:\n",
        "        question_id = item['id']\n",
        "        question_body = item['body']\n",
        "\n",
        "        processed_data['questions'].append({\n",
        "            'id': question_id,\n",
        "            'body': question_body,\n",
        "            'type': item['type'],\n",
        "            'ideal_answer': item['ideal_answer']\n",
        "        })\n",
        "\n",
        "        # Process documents\n",
        "        for doc in item['documents']:\n",
        "            if doc not in document_set:\n",
        "                document_set.add(doc)\n",
        "                processed_data['documents'].append({\n",
        "                    'id': f\"doc_{len(processed_data['documents'])}\",\n",
        "                    'url': doc\n",
        "                })\n",
        "            processed_data['question_documents'][question_id].add(doc)\n",
        "\n",
        "        # Process snippets\n",
        "        for snippet in item['snippets']:\n",
        "            snippet_text = snippet['text']\n",
        "            snippet_doc = snippet['document']\n",
        "            snippet_hash = hashlib.md5(snippet_text.encode()).hexdigest()\n",
        "\n",
        "            if snippet_hash not in snippet_set:\n",
        "                snippet_set.add(snippet_hash)\n",
        "                snippet_id = f\"snippet_{len(processed_data['snippets'])}\"\n",
        "                processed_data['snippets'].append({\n",
        "                    'id': snippet_id,\n",
        "                    'text': snippet_text,\n",
        "                    'document': snippet_doc,\n",
        "                    'begin_section': snippet['beginSection'],\n",
        "                    'end_section': snippet['endSection'],\n",
        "                    'offset_begin': snippet['offsetInBeginSection'],\n",
        "                    'offset_end': snippet['offsetInEndSection']\n",
        "                })\n",
        "                processed_data['document_snippets'][snippet_doc].append(snippet_id)\n",
        "\n",
        "    # Convert sets to lists for JSON serialization\n",
        "    processed_data['question_documents'] = {k: list(v) for k, v in processed_data['question_documents'].items()}\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Load BioBERT model\n",
        "model_name = \"dmis-lab/biobert-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get BioBERT embeddings\n",
        "def get_biobert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQEGTnOLkEim",
        "outputId": "d4176216-e776-47b9-a532-cdca8a520349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "file_path = 'heart_attack_dataset.json'\n",
        "preprocessed_data = preprocess_heart_attack_dataset(file_path)\n",
        "\n",
        "# Initialize Chroma client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Create a collection\n",
        "collection = client.create_collection(name=\"heart_attack_datad_biobeert\")\n",
        "\n",
        "# Prepare documents and snippets for embedding\n",
        "document_texts = [doc['url'] for doc in preprocessed_data['documents']]\n",
        "snippet_texts = [snippet['text'] for snippet in preprocessed_data['snippets']]\n",
        "all_texts = document_texts + snippet_texts\n",
        "\n",
        "# Get BioBERT embeddings\n",
        "all_embeddings = [get_biobert_embedding(text) for text in all_texts]\n",
        "\n",
        "# Add documents to the collection\n",
        "# When adding documents to the collection\n",
        "collection.add(\n",
        "    ids=[f\"doc_{i}\" for i in range(len(document_texts))],\n",
        "    documents=[f\"Content: {text}\\nSource: {url}\" for text, url in zip(document_texts, [doc['url'] for doc in preprocessed_data['documents']])],\n",
        "    embeddings=all_embeddings[:len(document_texts)]\n",
        ")\n",
        "\n",
        "# When adding snippets to the collection\n",
        "collection.add(\n",
        "    ids=[f\"snippet_{i}\" for i in range(len(snippet_texts))],\n",
        "    documents=[f\"Content: {text}\\nSource: {url}\" for text, url in zip(snippet_texts, [snippet['document'] for snippet in preprocessed_data['snippets']])],\n",
        "    embeddings=all_embeddings[len(document_texts):]\n",
        ")\n",
        "print(f\"Added {len(preprocessed_data['documents'])} documents and {len(preprocessed_data['snippets'])} snippets to the Chroma database.\")\n",
        "\n",
        "# Initialize the text generation model\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Function to query the collection and generate an answer\n",
        "def query_and_generate(query_text, n_results=3, max_new_tokens=100):\n",
        "    query_embedding = get_biobert_embedding(query_text)\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding.tolist()],\n",
        "        n_results=n_results\n",
        "    )\n",
        "\n",
        "    # Prepare context for generation\n",
        "    context = \"\"\n",
        "    for doc in results['documents'][0]:\n",
        "        context += f\"Document: {doc}\\n\\n\"\n",
        "\n",
        "    # Generation part\n",
        "    prompt = f\"Based on the following information:\\n{context}\\n\\nQuestion: {query_text}\\nAnswer:\"\n",
        "    generated_text = generator(prompt, max_new_tokens=max_new_tokens, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "    # Extract the generated answer (everything after \"Answer:\")\n",
        "    answer = generated_text.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "    return {\n",
        "        \"query\": query_text,\n",
        "        \"retrieved_documents\": results['documents'][0],\n",
        "        \"generated_answer\": answer\n",
        "    }\n",
        "\n",
        "# Example query\n",
        "query = \"What are the symptoms of a heart attack?\"\n",
        "result = query_and_generate(query)\n",
        "\n",
        "print(\"\\nQuery:\", result[\"query\"])\n",
        "print(\"\\nRetrieved Documents:\")\n",
        "for doc in result[\"retrieved_documents\"]:\n",
        "    print(f\"- {doc}\")\n",
        "print(\"\\nGenerated Answer:\", result[\"generated_answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xavENs_UkPFE",
        "outputId": "1a700ac7-418c-4e0a-d980-233ada1c17bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 100 documents and 143 snippets to the Chroma database.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What are the symptoms of a heart attack?\n",
            "\n",
            "Retrieved Documents:\n",
            "- Content: A heart attack is diagnosed using an ECG, blood tests for cardiac enzymes, and imaging tests like angiography.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/16563933\n",
            "- Content: An ECG detects irregular heart rhythms and damage to heart muscle, which are critical for diagnosing heart attacks.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/20672792\n",
            "- Content: Silent heart attacks show no obvious symptoms but can still cause significant heart damage and increase future heart attack risk.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/3185760\n",
            "\n",
            "Generated Answer: The patient must have severe muscle weakness or other cardiac arrhythmia. They may also experience blood clots in their muscles, especially as the heart beats less frequently. A heart attack is a more extreme type of heart attack and is characterized by the sudden death of the heart.\n",
            "\n",
            "A heart attack has been identified by researchers because it can take several minutes for the body to contract, allowing it to re-establish the oxygen saturation needed to revive a person's heart as the heart continues to beat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the role of nitric oxide in heart health?\"\n",
        "result = query_and_generate(query)\n",
        "\n",
        "print(\"\\nQuery:\", result[\"query\"])\n",
        "print(\"\\nRetrieved Documents:\")\n",
        "for doc in result[\"retrieved_documents\"]:\n",
        "    print(f\"- {doc}\")\n",
        "print(\"\\nGenerated Answer:\", result[\"generated_answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEHFlg0CmF0Q",
        "outputId": "8457be42-2513-4594-a63d-88d222497b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What is the role of nitric oxide in heart health?\n",
            "\n",
            "Retrieved Documents:\n",
            "- Content: Emerging research highlights the role of gut health and microbiota in cardiovascular health and heart attack prevention.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/19081153\n",
            "- Content: Vitamin D supports heart health by reducing inflammation, improving blood pressure, and enhancing vascular function.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/37087452\n",
            "- Content: Nitric oxide helps dilate blood vessels, improving blood flow and reducing blood pressure, thereby protecting against heart attacks.\n",
            "Source: http://www.ncbi.nlm.nih.gov/pubmed/20672792\n",
            "\n",
            "Generated Answer: Nitric oxide deficiency contributes to an increased risk for heart attacks and sudden deaths (T4DM) by anaerobic bacteria, or bacteria that are resistant to Nitric Oxides. A study published in this journal revealed that nitric oxide deficiency, when treated with antioxidants, reduces T4DM risk. Nitric oxide deficiency may be particularly beneficial in developing children or in developing adolescents who are allergic to certain types of antioxidant toxins.\n",
            "\n",
            "Researchers at the Institute of Medicine in Bethesda, Md., demonstrated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Evaluation"
      ],
      "metadata": {
        "id": "18izIPKetG0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn rouge-score numpy"
      ],
      "metadata": {
        "id": "MCOTr9h8mIi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "aa4558b6-cd78-409c-88ec-f7df818bd0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=373634d02f2aca1eeb6b277e475235c22880853f88b26bc3691f19baf785501d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import chromadb\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "import random\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Assuming you have functions: preprocess_heart_attack_dataset, get_biobert_embedding, query_and_generate\n",
        "\n",
        "def evaluate_rag(preprocessed_data, query_and_generate_func, num_queries=10):\n",
        "    \"\"\"\n",
        "    Evaluates the Retrieval-Augmented Generation (RAG) pipeline.\n",
        "\n",
        "    Args:\n",
        "        preprocessed_data (dict): The preprocessed dataset containing questions, documents, and snippets.\n",
        "        query_and_generate_func (function): The function to query the collection and generate an answer.\n",
        "        num_queries (int): The number of queries to sample for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the average retrieval and generation metrics.\n",
        "    \"\"\"\n",
        "    # Initialize metrics\n",
        "    retrieval_metrics = {\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': []\n",
        "    }\n",
        "    generation_metrics = {\n",
        "        'rouge1': [],\n",
        "        'rouge2': [],\n",
        "        'rougeL': []\n",
        "    }\n",
        "\n",
        "    # Initialize ROUGE scorer\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    # Sample questions for evaluation\n",
        "    sampled_questions = random.sample(preprocessed_data['questions'], min(num_queries, len(preprocessed_data['questions'])))\n",
        "\n",
        "    for question in sampled_questions:\n",
        "        # Get RAG results\n",
        "        rag_result = query_and_generate_func(question['body'])\n",
        "\n",
        "        # Evaluate retrieval\n",
        "        # Assuming the relevant document information is stored under 'context_documents' in the question dictionary\n",
        "        relevant_docs = set(question.get('context_documents', []))  # Handle cases where 'context_documents' might be missing\n",
        "        retrieved_docs = set([doc for doc in rag_result['retrieved_documents']])  # Modified to match the output format of query_and_generate\n",
        "\n",
        "        true_positives = len(relevant_docs.intersection(retrieved_docs))\n",
        "        false_positives = len(retrieved_docs - relevant_docs)\n",
        "        false_negatives = len(relevant_docs - retrieved_docs)\n",
        "\n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        retrieval_metrics['precision'].append(precision)\n",
        "        retrieval_metrics['recall'].append(recall)\n",
        "        retrieval_metrics['f1'].append(f1)\n",
        "\n",
        "        # Evaluate generation\n",
        "        reference_answer = ' '.join(question['ideal_answer'])\n",
        "        generated_answer = rag_result['generated_answer']  # Assuming 'generated_answer' key in rag_result\n",
        "\n",
        "        rouge_scores = scorer.score(reference_answer, generated_answer)\n",
        "\n",
        "        generation_metrics['rouge1'].append(rouge_scores['rouge1'].fmeasure)\n",
        "        generation_metrics['rouge2'].append(rouge_scores['rouge2'].fmeasure)\n",
        "        generation_metrics['rougeL'].append(rouge_scores['rougeL'].fmeasure)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_retrieval_metrics = {k: np.mean(v) for k, v in retrieval_metrics.items()}\n",
        "    avg_generation_metrics = {k: np.mean(v) for k, v in generation_metrics.items()}\n",
        "\n",
        "    return {\n",
        "        'retrieval': avg_retrieval_metrics,\n",
        "        'generation': avg_generation_metrics\n",
        "    }\n",
        "\n",
        "# Usage\n",
        "# Assuming you have preprocessed_data and query_and_generate function defined\n",
        "evaluation_results = evaluate_rag(preprocessed_data, query_and_generate, num_queries=10)\n",
        "print(\"Retrieval Metrics:\", evaluation_results['retrieval'])\n",
        "print(\"Generation Metrics:\", evaluation_results['generation'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU9jKhaZtKkZ",
        "outputId": "33055dcc-bc27-46af-b838-0bc907f5855b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
            "Generation Metrics: {'rouge1': 0.0961400765116628, 'rouge2': 0.013030654981874496, 'rougeL': 0.06914815387730222}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tp9BJNvatO__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# from collections import defaultdict\n",
        "# import hashlib\n",
        "# import torch\n",
        "# from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "# import chromadb\n",
        "# import numpy as np\n",
        "\n",
        "# def preprocess_heart_attack_dataset(file_path):\n",
        "#     with open(file_path, 'r') as f:\n",
        "#         data = json.load(f)\n",
        "\n",
        "#     processed_data = {\n",
        "#         'questions': [],\n",
        "#         'documents': [],\n",
        "#         'snippets': [],\n",
        "#         'document_snippets': defaultdict(list),\n",
        "#         'question_documents': defaultdict(set)\n",
        "#     }\n",
        "\n",
        "#     document_set = set()\n",
        "#     snippet_set = set()\n",
        "\n",
        "#     for item in data['questions']:\n",
        "#         question_id = item['id']\n",
        "#         question_body = item['body']\n",
        "\n",
        "#         processed_data['questions'].append({\n",
        "#             'id': question_id,\n",
        "#             'body': question_body,\n",
        "#             'type': item['type'],\n",
        "#             'ideal_answer': item['ideal_answer']\n",
        "#         })\n",
        "\n",
        "#         # Process documents\n",
        "#         for doc in item['documents']:\n",
        "#             if doc not in document_set:\n",
        "#                 document_set.add(doc)\n",
        "#                 processed_data['documents'].append({\n",
        "#                     'id': f\"doc_{len(processed_data['documents'])}\",\n",
        "#                     'url': doc\n",
        "#                 })\n",
        "#             processed_data['question_documents'][question_id].add(doc)\n",
        "\n",
        "#         # Process snippets\n",
        "#         for snippet in item['snippets']:\n",
        "#             snippet_text = snippet['text']\n",
        "#             snippet_doc = snippet['document']\n",
        "#             snippet_hash = hashlib.md5(snippet_text.encode()).hexdigest()\n",
        "\n",
        "#             if snippet_hash not in snippet_set:\n",
        "#                 snippet_set.add(snippet_hash)\n",
        "#                 snippet_id = f\"snippet_{len(processed_data['snippets'])}\"\n",
        "#                 processed_data['snippets'].append({\n",
        "#                     'id': snippet_id,\n",
        "#                     'text': snippet_text,\n",
        "#                     'document': snippet_doc,\n",
        "#                     'begin_section': snippet['beginSection'],\n",
        "#                     'end_section': snippet['endSection'],\n",
        "#                     'offset_begin': snippet['offsetInBeginSection'],\n",
        "#                     'offset_end': snippet['offsetInEndSection']\n",
        "#                 })\n",
        "#                 processed_data['document_snippets'][snippet_doc].append(snippet_id)\n",
        "\n",
        "#     # Convert sets to lists for JSON serialization\n",
        "#     processed_data['question_documents'] = {k: list(v) for k, v in processed_data['question_documents'].items()}\n",
        "\n",
        "#     return processed_data\n",
        "\n",
        "\n",
        "# # Load BioBERT model\n",
        "# model_name = \"dmis-lab/biobert-v1.1\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# # Function to get BioBERT embeddings\n",
        "# def get_biobert_embedding(text):\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs)\n",
        "#     return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "\n",
        "\n",
        "# # Function to aggregate snippets for each document\n",
        "# def aggregate_document_content(preprocessed_data):\n",
        "#     document_content = defaultdict(str)\n",
        "#     for snippet in preprocessed_data['snippets']:\n",
        "#         document_content[snippet['document']] += snippet['text'] + \" \"\n",
        "#     return document_content\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uC0hisu6ut82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Usage\n",
        "# file_path = 'heart_attack_dataset.json'\n",
        "# preprocessed_data = preprocess_heart_attack_dataset(file_path)\n",
        "\n",
        "# # Aggregate document content\n",
        "# document_content = aggregate_document_content(preprocessed_data)\n",
        "\n",
        "# # Initialize Chroma client\n",
        "# client = chromadb.Client()\n",
        "\n",
        "# # Create a collection\n",
        "# collection = client.create_collection(name=\"heart_attack_data_biobert_content\")\n",
        "\n",
        "# # Prepare documents for embedding\n",
        "# document_texts = []\n",
        "# document_urls = []\n",
        "# for doc in preprocessed_data['documents']:\n",
        "#     url = doc['url']\n",
        "#     content = document_content[url]\n",
        "#     if content:  # Only include documents with content\n",
        "#         document_texts.append(content)\n",
        "#         document_urls.append(url)\n",
        "\n",
        "# # Get BioBERT embeddings for document content\n",
        "# document_embeddings = [get_biobert_embedding(text) for text in document_texts]\n",
        "\n",
        "\n",
        "# # Add documents to the collection\n",
        "# collection.add(\n",
        "#     ids=[f\"doc_{i}\" for i in range(len(document_texts))],\n",
        "#     documents=[f\"Content: {text}\\nSource: {url}\" for text, url in zip(document_texts, document_urls)],\n",
        "#     embeddings=[embedding.tolist() for embedding in document_embeddings]\n",
        "# )\n",
        "\n",
        "# print(f\"Added {len(document_texts)} documents to the Chroma database.\")\n",
        "\n",
        "# # Initialize the text generation model\n",
        "# generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# # Function to query the collection and generate an answer\n",
        "# def query_and_generate(query_text, n_results=3, max_new_tokens=100):\n",
        "#     query_embedding = get_biobert_embedding(query_text)\n",
        "#     results = collection.query(\n",
        "#         query_embeddings=[query_embedding.tolist()],\n",
        "#         n_results=n_results\n",
        "#     )\n",
        "\n",
        "#     # Prepare context for generation\n",
        "#     context = \"\"\n",
        "#     for doc in results['documents'][0]:\n",
        "#         context += f\"{doc}\\n\\n\"\n",
        "\n",
        "#     # Generation part\n",
        "#     prompt = f\"Based on the following information:\\n{context}\\n\\nQuestion: {query_text}\\nAnswer:\"\n",
        "#     generated_text = generator(prompt, max_new_tokens=max_new_tokens, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "#     # Extract the generated answer (everything after \"Answer:\")\n",
        "#     answer = generated_text.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "#     return {\n",
        "#         \"query\": query_text,\n",
        "#         \"retrieved_documents\": results['documents'][0],\n",
        "#         \"generated_answer\": answer\n",
        "#     }\n",
        "\n",
        "# # Example queries\n",
        "# queries = [\n",
        "#     \"What are the symptoms of a heart attack?\",\n",
        "#     \"What is the role of nitric oxide in heart health?\"\n",
        "# ]\n",
        "\n",
        "# for query in queries:\n",
        "#     result = query_and_generate(query)\n",
        "#     print(\"\\nQuery:\", result[\"query\"])\n",
        "#     print(\"\\nRetrieved Documents:\")\n",
        "#     for doc in result[\"retrieved_documents\"]:\n",
        "#         print(f\"- {doc}\")\n",
        "#     print(\"\\nGenerated Answer:\", result[\"generated_answer\"])"
      ],
      "metadata": {
        "id": "fIYmFtWyuuZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ],
      "metadata": {
        "id": "Fur24kcZ3kVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_document_content(url, max_retries=3, delay=1):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Extract title\n",
        "            title = soup.find('meta', {'name': 'citation_title'})\n",
        "            title = title['content'] if title else ''\n",
        "\n",
        "            # Extract authors\n",
        "            authors = soup.find_all('meta', {'name': 'citation_author'})\n",
        "            authors = [author['content'] for author in authors]\n",
        "\n",
        "            # Extract abstract\n",
        "            abstract = soup.find('meta', {'name': 'description'})\n",
        "            abstract = abstract['content'] if abstract else ''\n",
        "\n",
        "            # Extract main content (this might need adjustment based on the actual structure)\n",
        "            main_content = soup.find('div', {'name': 'abstract'})\n",
        "            main_text = main_content.get_text(strip=True) if main_content else ''\n",
        "\n",
        "            content = f\"Title: {title}\\n\\nAuthors: {', '.join(authors)}\\n\\nAbstract: {abstract}\\n\\nMain Content: {main_text}\"\n",
        "\n",
        "            return content.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching content from {url}: {str(e)}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                return \"\"\n",
        "\n",
        "# Example usage\n",
        "url = \"https://pmc.ncbi.nlm.nih.gov/articles/PMC6820920/\"\n",
        "content = fetch_document_content(url)\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO1LSmov3lVX",
        "outputId": "012535d6-c6fe-4e6c-ac65-86ea58880467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pmc.ncbi.nlm.nih.gov:443\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6820920/ HTTP/11\" 200 None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Remotely controlled mandibular positioning of oral appliance therapy during polysomnography and drug-induced sleep endoscopy compared with conventional subjective titration in patients with obstructive sleep apnea: protocol for a randomized crossover trial\n",
            "\n",
            "Authors: Marijke Dieltjens, Marc J Braem, Sara Op de Beeck, Anneclaire V M T Vroegop, Elahe Kazemeini, Eli Van de Perck, Jolien Beyers, Chloé Kastoer, Kristien Wouters, Marc Willemen, Johan A Verbraecken, Olivier M Vanderveken\n",
            "\n",
            "Abstract: The amount of mandibular protrusion is a key factor in optimizing the efficacy of mandibular advancement device (MAD) therapy in an individual patient diagnosed with obstructive sleep apnea. This process is called titration and is generally based on ...\n",
            "\n",
            "Main Content:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install firecrawl beautifulsoup4 aiohttp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2gBAMH8-3-Yt",
        "outputId": "e65b6917-099a-4956-f85b-b1f9a01e7dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5InxxLZKhjLK",
        "outputId": "1536781a-fbd5-403a-bf0d-4cbe7224f368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scrapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Khu_Qhbcjh9f",
        "outputId": "0cf188f8-96ef-4549-f5f9-2e5ef2eaa04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scrapy\n",
            "  Using cached Scrapy-2.11.2-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.10.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.2.0)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy)\n",
            "  Using cached itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy)\n",
            "  Using cached parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scrapy) (1.7.0)\n",
            "Collecting service-identity>=18.1.0 (from scrapy)\n",
            "  Using cached service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (2.2.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (7.1.1)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.3.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (75.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.1)\n",
            "Collecting tldextract (from scrapy)\n",
            "  Using cached tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (5.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (24.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.1)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (24.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (4.12.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.32.3)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
            "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.16.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->Twisted>=18.9.0->scrapy) (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2024.8.30)\n",
            "Using cached Scrapy-2.11.2-py2.py3-none-any.whl (290 kB)\n",
            "Using cached itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Using cached parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
            "Using cached service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Using cached tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: parsel, requests-file, itemloaders, tldextract, service-identity, scrapy\n",
            "Successfully installed itemloaders-1.3.2 parsel-1.9.1 requests-file-2.1.0 scrapy-2.11.2 service-identity-24.2.0 tldextract-5.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl # installing firecrawl for AsyncCrawler"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn9E5XkgiaS3",
        "outputId": "33041a81-153a-4c08-8ee5-0f64a2eb9842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self, output_dir: str = \"scraped_data\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "        self.results = []\n",
        "\n",
        "    def extract_content(self, url: str) -> Dict:\n",
        "        \"\"\"Extract content from a webpage\"\"\"\n",
        "        logging.info(f\"Processing URL: {url}\")\n",
        "\n",
        "        try:\n",
        "            # Add delay between requests\n",
        "            time.sleep(1)\n",
        "\n",
        "            # Fetch the webpage\n",
        "            response = self.session.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse with BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Extract title (try different possible selectors)\n",
        "            title = None\n",
        "            for title_selector in ['h1.content-title', 'div.content-title', 'h1', 'title']:\n",
        "                title = soup.select_one(title_selector)\n",
        "                if title:\n",
        "                    break\n",
        "\n",
        "            # Extract abstract\n",
        "            abstract = None\n",
        "            for abstract_selector in ['div.abstract', 'abstract', 'div.article-abstract']:\n",
        "                abstract = soup.select_one(abstract_selector)\n",
        "                if abstract:\n",
        "                    break\n",
        "\n",
        "            # Initialize content dictionary\n",
        "            content = {\n",
        "                'url': url,\n",
        "                'title': title.text.strip() if title else None,\n",
        "                'abstract': abstract.text.strip() if abstract else None,\n",
        "                'sections': []\n",
        "            }\n",
        "\n",
        "            # Extract sections\n",
        "            for section in soup.find_all(['div', 'section'], class_=['section', 'sec']):\n",
        "                section_title = section.find(['h2', 'h3', 'title'])\n",
        "                section_content = section.find(['p', 'div'], class_=['section-content', 'p'])\n",
        "\n",
        "                if section_title and section_content:\n",
        "                    content['sections'].append({\n",
        "                        'title': section_title.text.strip(),\n",
        "                        'content': section_content.text.strip()\n",
        "                    })\n",
        "\n",
        "            # If no sections found, try to get main text content\n",
        "            if not content['sections']:\n",
        "                main_content = soup.find(['article', 'main', 'div.content'])\n",
        "                if main_content:\n",
        "                    paragraphs = main_content.find_all('p')\n",
        "                    content['main_text'] = '\\n'.join(p.text.strip() for p in paragraphs)\n",
        "\n",
        "            # Save individual article\n",
        "            article_id = url.split('/')[-1]\n",
        "            output_path = self.output_dir / f\"{article_id}.json\"\n",
        "\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(content, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            logging.info(f\"Successfully processed: {url}\")\n",
        "            return content\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing {url}: {str(e)}\")\n",
        "            return {'url': url, 'error': str(e)}\n",
        "\n",
        "    def process_urls(self, urls: List[str], max_workers: int = 2) -> List[Dict]:\n",
        "        \"\"\"Process multiple URLs concurrently\"\"\"\n",
        "        results = []\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            future_to_url = {executor.submit(self.extract_content, url): url for url in urls}\n",
        "\n",
        "            for future in as_completed(future_to_url):\n",
        "                url = future_to_url[future]\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    if result:\n",
        "                        results.append(result)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {url}: {str(e)}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "def process_dataset(dataset_path: str, output_dir: str = \"scraped_data\"):\n",
        "    \"\"\"Process the dataset and extract content from URLs\"\"\"\n",
        "    try:\n",
        "        # Read dataset\n",
        "        with open(dataset_path, 'r') as f:\n",
        "            dataset = json.load(f)\n",
        "\n",
        "        # Collect unique URLs\n",
        "        unique_urls = set()\n",
        "        for question in dataset['questions']:\n",
        "            unique_urls.update(question['documents'])\n",
        "\n",
        "        logging.info(f\"Found {len(unique_urls)} unique URLs to process\")\n",
        "\n",
        "        # Initialize scraper and process URLs\n",
        "        scraper = WebScraper(output_dir=output_dir)\n",
        "        results = scraper.process_urls(list(unique_urls))\n",
        "\n",
        "        # Save all results\n",
        "        with open(Path(output_dir) / \"all_articles.json\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        logging.info(f\"Successfully processed {len(results)} articles\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in process_dataset: {str(e)}\")\n",
        "        import traceback\n",
        "        logging.error(traceback.format_exc())\n",
        "        return []\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Process dataset\n",
        "    dataset_path = \"heart-attack-pmc-json.json\"\n",
        "    results = process_dataset(dataset_path)\n",
        "\n",
        "    # Print summary\n",
        "    successful = len([r for r in results if 'error' not in r])\n",
        "    logging.info(f\"Successfully processed {successful} out of {len(results)} articles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4r-qY-shUzf",
        "outputId": "667dcf74-7a91-46b9-e6ba-29aeb847d87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Found 7 unique URLs to process\n",
            "2024-11-06 03:46:59 [root] INFO: Found 7 unique URLs to process\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 03:46:59 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 03:46:59 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.ncbi.nlm.nih.gov:443\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): www.ncbi.nlm.nih.gov:443\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC6820920 HTTP/11\" 301 215\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pmc.ncbi.nlm.nih.gov:443\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC6450699 HTTP/11\" 301 216\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): pmc.ncbi.nlm.nih.gov:443\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6450699 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6820920 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6450699/ HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6820920/ HTTP/11\" 200 None\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 03:47:01 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 03:47:01 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 03:47:01 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\n",
            "2024-11-06 03:47:02 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\n",
            "DEBUG:urllib3.connectionpool:Resetting dropped connection: www.ncbi.nlm.nih.gov\n",
            "DEBUG:urllib3.connectionpool:Resetting dropped connection: www.ncbi.nlm.nih.gov\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC5332475 HTTP/11\" 301 215\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC5752199 HTTP/11\" 301 215\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5332475 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5752199 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5752199/ HTTP/11\" 404 None\n",
            "ERROR:root:Error processing https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199: 404 Client Error: Not Found for url: https://pmc.ncbi.nlm.nih.gov/articles/PMC5752199/\n",
            "2024-11-06 03:47:03 [root] ERROR: Error processing https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199: 404 Client Error: Not Found for url: https://pmc.ncbi.nlm.nih.gov/articles/PMC5752199/\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6277075\n",
            "2024-11-06 03:47:03 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6277075\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5332475/ HTTP/11\" 200 None\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 03:47:03 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284956\n",
            "2024-11-06 03:47:03 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284956\n",
            "DEBUG:urllib3.connectionpool:Resetting dropped connection: www.ncbi.nlm.nih.gov\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC6277075 HTTP/11\" 301 215\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6277075 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC6277075/ HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC7284956 HTTP/11\" 301 216\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC7284956 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC7284956/ HTTP/11\" 200 None\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6277075\n",
            "2024-11-06 03:47:05 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6277075\n",
            "INFO:root:Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864679\n",
            "2024-11-06 03:47:05 [root] INFO: Processing URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864679\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284956\n",
            "2024-11-06 03:47:05 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284956\n",
            "DEBUG:urllib3.connectionpool:Resetting dropped connection: www.ncbi.nlm.nih.gov\n",
            "DEBUG:urllib3.connectionpool:https://www.ncbi.nlm.nih.gov:443 \"GET /pmc/articles/PMC5864679 HTTP/11\" 301 216\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5864679 HTTP/11\" 301 0\n",
            "DEBUG:urllib3.connectionpool:https://pmc.ncbi.nlm.nih.gov:443 \"GET /articles/PMC5864679/ HTTP/11\" 200 None\n",
            "INFO:root:Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864679\n",
            "2024-11-06 03:47:07 [root] INFO: Successfully processed: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864679\n",
            "INFO:root:Successfully processed 7 articles\n",
            "2024-11-06 03:47:07 [root] INFO: Successfully processed 7 articles\n",
            "INFO:root:Successfully processed 6 out of 7 articles\n",
            "2024-11-06 03:47:07 [root] INFO: Successfully processed 6 out of 7 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio\n",
        "from typing import List, Dict\n",
        "# Try importing directly from firecrawl or upgrade the package using !pip install firecrawl-py --upgrade\n",
        "from firecrawl.crawler import AsyncCrawler\n",
        "from bs4 import BeautifulSoup\n",
        "import aiohttp\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class PMCCrawler:\n",
        "    def __init__(self, output_dir: str = \"scraped_data\"):\n",
        "        self.crawler = AsyncCrawler(\n",
        "            concurrent_requests=2,  # Respect rate limits\n",
        "            delay_between_requests=1.0  # 1 second delay between requests\n",
        "        )\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    async def extract_article_content(self, html: str, url: str) -> Dict:\n",
        "        \"\"\"Extract relevant content from PMC article HTML.\"\"\"\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "        # Extract article metadata\n",
        "        title = soup.find('h1', {'class': 'content-title'})\n",
        "        abstract = soup.find('div', {'class': 'abstract'})\n",
        "\n",
        "        content = {\n",
        "            'url': url,\n",
        "            'title': title.text.strip() if title else None,\n",
        "            'abstract': abstract.text.strip() if abstract else None,\n",
        "            'sections': []\n",
        "        }\n",
        "\n",
        "        # Extract main content sections\n",
        "        for section in soup.find_all('div', {'class': 'section'}):\n",
        "            section_title = section.find('h2')\n",
        "            section_content = section.find('div', {'class': 'section-content'})\n",
        "\n",
        "            if section_title and section_content:\n",
        "                content['sections'].append({\n",
        "                    'title': section_title.text.strip(),\n",
        "                    'content': section_content.text.strip()\n",
        "                })\n",
        "\n",
        "        return content\n",
        "\n",
        "    async def process_dataset(self, dataset_path: str):\n",
        "        \"\"\"Process the dataset and crawl all unique URLs.\"\"\"\n",
        "        with open(dataset_path, 'r') as f:\n",
        "            dataset = json.load(f)\n",
        "\n",
        "        # Collect unique URLs\n",
        "        unique_urls = set(\n",
        "                \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\",\n",
        "                \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\",\n",
        "                \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\",\n",
        "                \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\")\n",
        "        # for question in dataset['questions']:\n",
        "        #     unique_urls.update(question['documents'])\n",
        "\n",
        "        # logging.info(f\"Found {len(unique_urls)} unique URLs to process\")\n",
        "\n",
        "        # Crawl each URL\n",
        "        results = []\n",
        "        async for response in self.crawler.crawl(list(unique_urls)):\n",
        "            if response.status == 200:\n",
        "                try:\n",
        "                    content = await self.extract_article_content(\n",
        "                        response.text,\n",
        "                        response.url\n",
        "                    )\n",
        "                    results.append(content)\n",
        "\n",
        "                    # Save individual article\n",
        "                    article_id = response.url.split('/')[-1]\n",
        "                    output_path = self.output_dir / f\"{article_id}.json\"\n",
        "                    with open(output_path, 'w') as f:\n",
        "                        json.dump(content, f, indent=2)\n",
        "\n",
        "                    logging.info(f\"Successfully processed {response.url}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {response.url}: {str(e)}\")\n",
        "            else:\n",
        "                logging.warning(f\"Failed to fetch {response.url}: {response.status}\")\n",
        "\n",
        "        # Save complete results\n",
        "        with open(self.output_dir / \"all_articles.json\", 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        return results\n",
        "\n",
        "async def main():\n",
        "    # Initialize crawler\n",
        "    crawler = PMCCrawler(output_dir=\"pmc_articles\")\n",
        "\n",
        "\n",
        "    # Process dataset\n",
        "    # dataset_path = \"heart-attack-pmc-json.json\"  # Update with your dataset path\n",
        "    try:\n",
        "        results = await crawler.process_dataset()\n",
        "        logging.info(f\"Successfully processed {len(results)} articles\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing dataset: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "5UKpV54bhZFH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "50dc7da5-e93c-47f9-f5bd-f9228b5f9cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'firecrawl.crawler'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a58e6ef87f21>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Try importing directly from firecrawl or upgrade the package using !pip install firecrawl-py --upgrade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfirecrawl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsyncCrawler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiohttp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'firecrawl.crawler'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl beautifulsoup4 aiohttp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w_mb8eZoxWzN",
        "outputId": "d2af36ca-23a5-411a-c479-e22d6ff05b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl) (1.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl-py # install the firecrawl-py package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBmha9sryRV7",
        "outputId": "84d5bf2b-cf68-4cf4-b57b-3714f0ff6dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl-py --upgrade  # Try upgrading the package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5er4D2nvyrmX",
        "outputId": "13665c55-3494-4d7a-87bb-61192f184455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from firecrawl import AsyncCrawler  # Try importing directly from firecrawl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "WLIBPWV-y_GP",
        "outputId": "ffcd415e-f875-4abf-c551-dff9209b22ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AsyncCrawler' from 'firecrawl' (/usr/local/lib/python3.10/dist-packages/firecrawl/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5cbe5f5bc70e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfirecrawl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsyncCrawler\u001b[0m  \u001b[0;31m# Try importing directly from firecrawl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AsyncCrawler' from 'firecrawl' (/usr/local/lib/python3.10/dist-packages/firecrawl/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firecrawl-py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nWjepMSzBTP",
        "outputId": "f1c8b368-7754-4e26-f196-4c184ca55385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firecrawl-py in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.0.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (13.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio\n",
        "from typing import List, Dict\n",
        "from bs4 import BeautifulSoup\n",
        "import aiohttp\n",
        "import logging\n",
        "import nest_asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "# Enable nested async support for Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "class AsyncWebScraper:\n",
        "    def __init__(self, output_dir: str = \"scraped_data\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.semaphore = asyncio.Semaphore(2)  # Limit concurrent requests\n",
        "\n",
        "    async def fetch_url(self, session: aiohttp.ClientSession, url: str) -> Dict:\n",
        "        \"\"\"Fetch and process a single URL with rate limiting.\"\"\"\n",
        "        async with self.semaphore:  # Limit concurrent requests\n",
        "            try:\n",
        "                # Add delay for rate limiting\n",
        "                await asyncio.sleep(1)\n",
        "\n",
        "                async with session.get(url) as response:\n",
        "                    logging.info(f\"Fetching {url}\")\n",
        "                    if response.status == 200:\n",
        "                        html = await response.text()\n",
        "                        logging.info(f\"Successfully fetched {url}\")\n",
        "                        content = await self.extract_article_content(html, url)\n",
        "\n",
        "                        # Save individual article\n",
        "                        article_id = url.split('/')[-1]\n",
        "                        output_path = self.output_dir / f\"{article_id}.json\"\n",
        "\n",
        "                        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                            json.dump(content, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "                        logging.info(f\"Successfully processed {url}\")\n",
        "                        return content\n",
        "                    else:\n",
        "                        error_msg = f\"Failed to fetch {url}: HTTP {response.status}\"\n",
        "                        logging.warning(error_msg)\n",
        "                        return {\"url\": url, \"error\": error_msg}\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error processing {url}: {str(e)}\"\n",
        "                logging.error(error_msg)\n",
        "                return {\"url\": url, \"error\": error_msg}\n",
        "\n",
        "    async def extract_article_content(self, html: str, url: str) -> Dict:\n",
        "        \"\"\"Extract relevant content from HTML.\"\"\"\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        logging.info(f\"Extracting content from {url}\")\n",
        "\n",
        "        # Try multiple selectors for title\n",
        "        title = None\n",
        "        for selector in ['h1.content-title', 'div.content-title', 'h1', '.article-title']:\n",
        "            title = soup.select_one(selector)\n",
        "            if title:\n",
        "                logging.info(f\"Found title using selector: {selector}\")\n",
        "                break\n",
        "\n",
        "        # Try multiple selectors for abstract\n",
        "        abstract = None\n",
        "        for selector in ['div.abstract', 'abstract', '.article-abstract', '#abstract',\"body main-article-body\"]:\n",
        "            abstract = soup.select_one(selector[4])\n",
        "            if abstract:\n",
        "                logging.info(f\"Found abstract using selector: {selector}\")\n",
        "                break\n",
        "\n",
        "        content = {\n",
        "            'url': url,\n",
        "            'title': title.text.strip() if title else None,\n",
        "            'abstract': abstract.text.strip() if abstract else None,\n",
        "            'sections': []\n",
        "        }\n",
        "\n",
        "        # Extract main content sections\n",
        "        sections = soup.find_all(['div', 'section'], class_=['section', 'sec'])\n",
        "\n",
        "        for section in sections:\n",
        "            section_title = section.find(['h2', 'h3', 'title'])\n",
        "            section_content = section.find(['p', 'div'], class_=['section-content', 'p'])\n",
        "\n",
        "            if section_title and section_content:\n",
        "                content['sections'].append({\n",
        "                    'title': section_title.text.strip(),\n",
        "                    'content': section_content.text.strip()\n",
        "                })\n",
        "                logging.info(f\"Found section: {section_title.text.strip()[:50]}...\")\n",
        "\n",
        "        # If no sections found, try to get main text\n",
        "        if not content['sections']:\n",
        "            logging.info(\"No sections found, trying to extract main text\")\n",
        "            main_content = soup.find(['article', 'main', 'div.content'])\n",
        "            if main_content:\n",
        "                paragraphs = main_content.find_all('p')\n",
        "                content['main_text'] = '\\n'.join(p.text.strip() for p in paragraphs)\n",
        "\n",
        "        return content\n",
        "\n",
        "    async def process_urls(self, urls: List[str]) -> List[Dict]:\n",
        "        \"\"\"Process multiple URLs concurrently.\"\"\"\n",
        "        timeout = aiohttp.ClientTimeout(total=60)  # 60 seconds timeout\n",
        "\n",
        "        async with aiohttp.ClientSession(\n",
        "            headers={\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            },\n",
        "            timeout=timeout\n",
        "        ) as session:\n",
        "            tasks = []\n",
        "            for url in urls:\n",
        "                tasks.append(asyncio.ensure_future(self.fetch_url(session, url)))\n",
        "\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Save complete results\n",
        "            with open(self.output_dir / \"all_articles.json\", 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            return results\n",
        "\n",
        "# Create an instance of the scraper\n",
        "scraper = AsyncWebScraper(output_dir=\"pmc_articles\")\n",
        "\n",
        "# Define URLs to process\n",
        "urls = [\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\"\n",
        "]\n",
        "\n",
        "# Function to run the scraper\n",
        "async def run_scraper():\n",
        "    try:\n",
        "        results = await scraper.process_urls(urls)\n",
        "\n",
        "        # Print summary\n",
        "        successful = len([r for r in results if 'error' not in r])\n",
        "        logging.info(f\"Successfully processed {successful} out of {len(results)} articles\")\n",
        "\n",
        "        # Print first successful article title if any\n",
        "        for result in results:\n",
        "            if 'title' in result and result['title']:\n",
        "                logging.info(f\"Sample article title: {result['title']}\")\n",
        "                break\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in run_scraper: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# To run in Jupyter:\n",
        "results = await run_scraper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xt6O9sBzQC5",
        "outputId": "17800727-f0db-4fcd-92b4-25256b1edb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\n",
            "2024-11-06 05:05:15 [root] INFO: Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199\n",
            "WARNING:root:Failed to fetch https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199: HTTP 404\n",
            "2024-11-06 05:05:15 [root] WARNING: Failed to fetch https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752199: HTTP 404\n",
            "INFO:root:Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 05:05:17 [root] INFO: Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 05:05:17 [root] INFO: Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 05:05:17 [root] INFO: Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Found title using selector: h1\n",
            "2024-11-06 05:05:17 [root] INFO: Found title using selector: h1\n",
            "INFO:root:Found abstract using selector: div.abstract\n",
            "2024-11-06 05:05:17 [root] INFO: Found abstract using selector: div.abstract\n",
            "INFO:root:No sections found, trying to extract main text\n",
            "2024-11-06 05:05:18 [root] INFO: No sections found, trying to extract main text\n",
            "INFO:root:Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "2024-11-06 05:05:18 [root] INFO: Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820920\n",
            "INFO:root:Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 05:05:18 [root] INFO: Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "INFO:root:Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 05:05:18 [root] INFO: Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "INFO:root:Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 05:05:19 [root] INFO: Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "INFO:root:Found title using selector: h1\n",
            "2024-11-06 05:05:19 [root] INFO: Found title using selector: h1\n",
            "INFO:root:Found abstract using selector: div.abstract\n",
            "2024-11-06 05:05:19 [root] INFO: Found abstract using selector: div.abstract\n",
            "INFO:root:No sections found, trying to extract main text\n",
            "2024-11-06 05:05:19 [root] INFO: No sections found, trying to extract main text\n",
            "INFO:root:Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "2024-11-06 05:05:19 [root] INFO: Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6450699\n",
            "INFO:root:Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 05:05:19 [root] INFO: Fetching https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 05:05:19 [root] INFO: Successfully fetched https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 05:05:19 [root] INFO: Extracting content from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Found title using selector: h1\n",
            "2024-11-06 05:05:19 [root] INFO: Found title using selector: h1\n",
            "INFO:root:Found abstract using selector: div.abstract\n",
            "2024-11-06 05:05:19 [root] INFO: Found abstract using selector: div.abstract\n",
            "INFO:root:No sections found, trying to extract main text\n",
            "2024-11-06 05:05:19 [root] INFO: No sections found, trying to extract main text\n",
            "INFO:root:Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "2024-11-06 05:05:19 [root] INFO: Successfully processed https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332475\n",
            "INFO:root:Successfully processed 3 out of 4 articles\n",
            "2024-11-06 05:05:19 [root] INFO: Successfully processed 3 out of 4 articles\n",
            "INFO:root:Sample article title: Remotely controlled mandibular positioning of oral appliance therapy during polysomnography and drug-induced sleep endoscopy compared with conventional subjective titration in patients with obstructive sleep apnea: protocol for a randomized crossover trial\n",
            "2024-11-06 05:05:19 [root] INFO: Sample article title: Remotely controlled mandibular positioning of oral appliance therapy during polysomnography and drug-induced sleep endoscopy compared with conventional subjective titration in patients with obstructive sleep apnea: protocol for a randomized crossover trial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp beautifulsoup4 nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_9uE0AtzfXq",
        "outputId": "02973ee4-89fe-44bf-a76b-ea2bbbbaa95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium webdriver_manager"
      ],
      "metadata": {
        "id": "X2adB7jmzthh",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17199ce-d96b-4d0c-9f1a-0282d7676fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.4.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, python-dotenv, outcome, webdriver_manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 python-dotenv-1.0.1 selenium-4.26.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 webdriver_manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import os\n",
        "# import time\n",
        "# from pathlib import Path\n",
        "# import undetected_chromedriver as uc\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from selenium.webdriver.support.ui import WebDriverWait\n",
        "# from selenium.webdriver.support import expected_conditions as EC\n",
        "# from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "# import logging\n",
        "# import re\n",
        "\n",
        "\n",
        "\n",
        "# # Configure logging\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "# )\n",
        "\n",
        "# class PMCPDFDownloader:\n",
        "#     def __init__(self, download_dir: str = \"pmc_pdfs\"):\n",
        "#         self.download_dir = Path(download_dir).absolute()\n",
        "#         self.download_dir.mkdir(exist_ok=True)\n",
        "\n",
        "#         # Setup Chrome options\n",
        "#         self.options = uc.ChromeOptions()\n",
        "#         self.options.add_argument('--headless')  # Run in headless mode\n",
        "#         self.options.add_argument('--no-sandbox')\n",
        "#         self.options.add_argument('--disable-dev-shm-usage')\n",
        "#         self.options.add_experimental_option(\n",
        "#             \"prefs\",\n",
        "#             {\n",
        "#                 \"download.default_directory\": str(self.download_dir),\n",
        "#                 \"download.prompt_for_download\": False,\n",
        "#                 \"download.directory_upgrade\": True,\n",
        "#                 \"plugins.always_open_pdf_externally\": True,\n",
        "#                 \"profile.default_content_settings.popups\": 0\n",
        "#             }\n",
        "#         )\n",
        "\n",
        "#     def setup_driver(self):\n",
        "#         \"\"\"Initialize and return undetected ChromeDriver\"\"\"\n",
        "#         try:\n",
        "#             driver = uc.Chrome(\n",
        "#                 options=self.options,\n",
        "#                 driver_executable_path='/usr/bin/chromedriver'\n",
        "#             )\n",
        "#             return driver\n",
        "#         except Exception as e:\n",
        "#             logging.error(f\"Error setting up Chrome driver: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def extract_pmcid(self, url: str) -> str:\n",
        "#         \"\"\"Extract PMCID from URL\"\"\"\n",
        "#         match = re.search(r'PMC\\d+', url)\n",
        "#         return match.group(0) if match else None\n",
        "\n",
        "#     def get_direct_pdf_link(self, driver, url: str) -> str:\n",
        "#         \"\"\"Get direct PDF download link from PMC page\"\"\"\n",
        "#         try:\n",
        "#             driver.get(url)\n",
        "#             wait = WebDriverWait(driver, 10)\n",
        "#             pdf_link = wait.until(\n",
        "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"a[title='Download PDF']\"))\n",
        "#             )\n",
        "#             return pdf_link.get_attribute('href')\n",
        "#         except Exception as e:\n",
        "#             logging.error(f\"Error getting PDF link from {url}: {str(e)}\")\n",
        "#             return None\n",
        "\n",
        "#     def download_pdf(self, driver, url: str, question_id: str) -> bool:\n",
        "#         \"\"\"Download PDF for a single PMC article\"\"\"\n",
        "#         try:\n",
        "#             logging.info(f\"Processing {url} for question {question_id}\")\n",
        "\n",
        "#             # Get direct PDF link\n",
        "#             pdf_url = self.get_direct_pdf_link(driver, url)\n",
        "#             if not pdf_url:\n",
        "#                 logging.error(f\"Could not get PDF link for {url}\")\n",
        "#                 return False\n",
        "\n",
        "#             # Get PMCID for filename\n",
        "#             pmcid = self.extract_pmcid(url)\n",
        "#             if not pmcid:\n",
        "#                 logging.error(f\"Could not extract PMCID from {url}\")\n",
        "#                 return False\n",
        "\n",
        "#             # Construct the new filename\n",
        "#             new_filename = f\"{pmcid}_{question_id}.pdf\"\n",
        "#             output_path = self.download_dir / new_filename\n",
        "\n",
        "#             # Use wget to download the PDF\n",
        "#             !wget -O \"{output_path}\" \"{pdf_url}\"\n",
        "\n",
        "#             if output_path.exists() and output_path.stat().st_size > 0:\n",
        "#                 logging.info(f\"Successfully downloaded {new_filename}\")\n",
        "#                 return True\n",
        "#             else:\n",
        "#                 logging.error(f\"Failed to download {new_filename}\")\n",
        "#                 return False\n",
        "\n",
        "#         except Exception as e:\n",
        "#             logging.error(f\"Error downloading PDF from {url}: {str(e)}\")\n",
        "#             return False\n",
        "\n",
        "#     def process_dataset(self, dataset_path: str):\n",
        "#         \"\"\"Process entire dataset and download PDFs\"\"\"\n",
        "#         try:\n",
        "#             # Read dataset\n",
        "#             with open(dataset_path, 'r') as f:\n",
        "#                 dataset = json.load(f)\n",
        "\n",
        "#             # Initialize web driver\n",
        "#             driver = self.setup_driver()\n",
        "\n",
        "#             try:\n",
        "#                 # Process each question and its documents\n",
        "#                 for question in dataset['questions']:\n",
        "#                     question_id = question['id']\n",
        "\n",
        "#                     for url in question['documents']:\n",
        "#                         success = self.download_pdf(driver, url, question_id)\n",
        "#                         if not success:\n",
        "#                             logging.warning(f\"Failed to download PDF for {url}\")\n",
        "\n",
        "#                         # Add delay between downloads\n",
        "#                         time.sleep(2)\n",
        "\n",
        "#             finally:\n",
        "#                 # Always close the driver\n",
        "#                 driver.quit()\n",
        "\n",
        "#         except Exception as e:\n",
        "#             logging.error(f\"Error processing dataset: {str(e)}\")\n",
        "#             import traceback\n",
        "#             logging.error(traceback.format_exc())\n",
        "\n",
        "# # Function to run the downloader\n",
        "# def run_downloader(dataset_path: str):\n",
        "#     # Initialize downloader\n",
        "#     downloader = PMCPDFDownloader(download_dir=\"pmc_pdfs\")\n",
        "\n",
        "#     # Process dataset\n",
        "#     downloader.process_dataset(dataset_path)\n",
        "\n",
        "# # Example usage:\n",
        "# dataset_path = \"heart-attack-pmc-json.json\"\n",
        "# run_downloader(dataset_path)"
      ],
      "metadata": {
        "id": "uCaJtgs9FGoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # First, install required packages\n",
        "# !pip install undetected-chromedriver\n",
        "# !apt-get update\n",
        "# !apt install chromium-chromedriver\n",
        "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "# !pip install selenium"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1w0_JnKbFL8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T17RS6D-F2od"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}