{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d725e4-4c7e-42d4-bdd1-5bfc6a06d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.9.11-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.9.1 regex-2024.9.11\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0bce8-293c-498b-82da-8f87996c7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9901a610-1703-4bf8-aadf-15f8661f345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tharun\\anaconda3\\envs\\env_pytorch\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 8.4/9.9 MB 47.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 43.9 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp38-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.1-cp38-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 34.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.1 transformers-4.45.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0921d2c4-f08e-4406-b0af-3170095e77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8caaf3-30d4-4448-b027-b3adc0154a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0928004b-b71d-4a64-bf11-2b5029980ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d329c31c-b081-46be-8d5f-7d49a5580b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    words = simple_tokenize(text)\n",
    "    tfidf = TfidfVectorizer().fit_transform([text])\n",
    "    important_words = [word for word, score in sorted(zip(words, tfidf.toarray()[0]), key=lambda x: x[1], reverse=True)[:10]]\n",
    "    return [(word, \"KEYWORD\") for word in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0566cd18-ad95-4691-bb54-df3cb987a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    dataset = load_dataset(\"GBaker/MedQA-USMLE-4-options\")\n",
    "    def preprocess(data):\n",
    "        return {\n",
    "            'question': data['question'],\n",
    "            'answer': data['answer'],\n",
    "            'options': data['options'],\n",
    "            'meta_info': data['meta_info']\n",
    "        }\n",
    "    preprocessed_data = dataset.map(preprocess)\n",
    "    df = pd.DataFrame(preprocessed_data['train'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee6a1c74-3e8b-46ed-8f26-f89fbdd20f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and preprocessed.\n",
      "Connected to Neo4j database.\n",
      "Processed question 1\n",
      "Processed question 2\n",
      "Processed question 3\n",
      "Processed question 4\n",
      "Processed question 5\n",
      "Processed question 6\n",
      "Processed question 7\n",
      "Processed question 8\n",
      "Processed question 9\n",
      "Processed question 10\n",
      "Processed question 11\n",
      "Processed question 12\n",
      "Processed question 13\n",
      "Processed question 14\n",
      "Processed question 15\n",
      "Processed question 16\n",
      "Processed question 17\n",
      "Processed question 18\n",
      "Processed question 19\n",
      "Processed question 20\n",
      "Processed question 21\n",
      "Processed question 22\n",
      "Processed question 23\n",
      "Processed question 24\n",
      "Processed question 25\n",
      "Processed question 26\n",
      "Processed question 27\n",
      "Processed question 28\n",
      "Processed question 29\n",
      "Processed question 30\n",
      "Processed question 31\n",
      "Processed question 32\n",
      "Processed question 33\n",
      "Processed question 34\n",
      "Processed question 35\n",
      "Processed question 36\n",
      "Processed question 37\n",
      "Processed question 38\n",
      "Processed question 39\n",
      "Processed question 40\n",
      "Processed question 41\n",
      "Processed question 42\n",
      "Processed question 43\n",
      "Processed question 44\n",
      "Processed question 45\n",
      "Processed question 46\n",
      "Processed question 47\n",
      "Processed question 48\n",
      "Processed question 49\n",
      "Processed question 50\n",
      "Processed question 51\n",
      "Processed question 52\n",
      "Processed question 53\n",
      "Processed question 54\n",
      "Processed question 55\n",
      "Processed question 56\n",
      "Processed question 57\n",
      "Processed question 58\n",
      "Processed question 59\n",
      "Processed question 60\n",
      "Processed question 61\n",
      "Processed question 62\n",
      "Processed question 63\n",
      "Processed question 64\n",
      "Processed question 65\n",
      "Processed question 66\n",
      "Processed question 67\n",
      "Processed question 68\n",
      "Processed question 69\n",
      "Processed question 70\n",
      "Processed question 71\n",
      "Processed question 72\n",
      "Processed question 73\n",
      "Processed question 74\n",
      "Processed question 75\n",
      "Processed question 76\n",
      "Processed question 77\n",
      "Processed question 78\n",
      "Processed question 79\n",
      "Processed question 80\n",
      "Processed question 81\n",
      "Processed question 82\n",
      "Processed question 83\n",
      "Processed question 84\n",
      "Processed question 85\n",
      "Processed question 86\n",
      "Processed question 87\n",
      "Processed question 88\n",
      "Processed question 89\n",
      "Processed question 90\n",
      "Processed question 91\n",
      "Processed question 92\n",
      "Processed question 93\n",
      "Processed question 94\n",
      "Processed question 95\n",
      "Processed question 96\n",
      "Processed question 97\n",
      "Processed question 98\n",
      "Processed question 99\n",
      "Processed question 100\n",
      "Question: A 3-month-old baby died suddenly at night while asleep. His mother noticed that he had died only after she awoke in the morning. No cause of death was determined based on the autopsy. Which of the following precautions could have prevented the death of the baby?\n",
      "Generated Answer: Placing the infant in a supine position on a firm mattress while sleeping\n",
      "Ground Truth: Placing the infant in a supine position on a firm mattress while sleeping\n",
      "BLEU Score: 1.0\n",
      "Knowledge graph construction and evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "class MedicalKnowledgeGraph:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def create_entity(self, entity_type, name):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MERGE (a:\" + entity_type + \" {name: $name})\", name=name)\n",
    "\n",
    "    def create_relationship(self, entity1_type, entity1_name, relation, entity2_type, entity2_name):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                MATCH (a:\"\"\" + entity1_type + \"\"\" {name: $entity1_name})\n",
    "                MATCH (b:\"\"\" + entity2_type + \"\"\" {name: $entity2_name})\n",
    "                MERGE (a)-[r:\"\"\" + relation + \"\"\"]->(b)\n",
    "                \"\"\", entity1_name=entity1_name, entity2_name=entity2_name)\n",
    "\n",
    "    def add_qa_pair(self, question, answer):\n",
    "        entities = extract_entities(question)\n",
    "        q_embedding = get_bert_embedding(question).tolist()\n",
    "        a_embedding = get_bert_embedding(answer).tolist()\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                CREATE (q:Question {text: $question, embedding: $q_embedding})\n",
    "                CREATE (a:Answer {text: $answer, embedding: $a_embedding})\n",
    "                CREATE (q)-[:HAS_ANSWER]->(a)\n",
    "            \"\"\", question=question, answer=answer, q_embedding=q_embedding, a_embedding=a_embedding)\n",
    "            \n",
    "            for entity, entity_type in entities:\n",
    "                session.run(\"\"\"\n",
    "                    MATCH (q:Question {text: $question})\n",
    "                    MERGE (e:Entity {name: $entity, type: $entity_type})\n",
    "                    CREATE (q)-[:CONTAINS]->(e)\n",
    "                \"\"\", question=question, entity=entity, entity_type=entity_type)\n",
    "\n",
    "    def get_answer(self, question):\n",
    "        q_embedding = get_bert_embedding(question)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (q:Question)-[:HAS_ANSWER]->(a:Answer)\n",
    "                RETURN q.embedding AS q_embedding, a.text AS answer\n",
    "            \"\"\")\n",
    "            \n",
    "            embeddings = []\n",
    "            answers = []\n",
    "            for record in result:\n",
    "                embeddings.append(record[\"q_embedding\"])\n",
    "                answers.append(record[\"answer\"])\n",
    "            \n",
    "            if not embeddings:\n",
    "                return \"No answer found.\"\n",
    "            \n",
    "            similarities = cosine_similarity([q_embedding], embeddings)[0]\n",
    "            most_similar_index = np.argmax(similarities)\n",
    "            \n",
    "            return answers[most_similar_index]\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    ref_tokens = simple_tokenize(reference)\n",
    "    cand_tokens = simple_tokenize(candidate)\n",
    "    \n",
    "    max_n = min(4, len(ref_tokens), len(cand_tokens))\n",
    "    precisions = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ref_ngrams = set(zip(*[ref_tokens[i:] for i in range(n)]))\n",
    "        cand_ngrams = list(zip(*[cand_tokens[i:] for i in range(n)]))\n",
    "        matches = sum(1 for ngram in cand_ngrams if ngram in ref_ngrams)\n",
    "        precisions.append(matches / len(cand_ngrams) if cand_ngrams else 0)\n",
    "    \n",
    "    bp = min(1, len(cand_tokens) / len(ref_tokens)) if len(ref_tokens) > 0 else 0\n",
    "    \n",
    "    if all(p > 0 for p in precisions):\n",
    "        s = (sum(map(lambda x: math.log(x), precisions)) / len(precisions))\n",
    "        return bp * math.exp(s)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def answer_question(graph, question, ground_truth):\n",
    "    answer = graph.get_answer(question)\n",
    "    bleu_score = calculate_bleu(ground_truth, answer)\n",
    "    return answer, bleu_score\n",
    "\n",
    "def main():\n",
    "    df = load_and_preprocess_data()\n",
    "    print(\"Dataset loaded and preprocessed.\")\n",
    "\n",
    "    graph = MedicalKnowledgeGraph(\"bolt://localhost:7687\", \"neo4j\", \"123456789\")\n",
    "    print(\"Connected to Neo4j database.\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        graph.add_qa_pair(question, answer)\n",
    "        print(f\"Processed question {index + 1}\")\n",
    "        if index == 99:  # Process only 100 questions for demonstration\n",
    "            break\n",
    "\n",
    "    sample_question = df.iloc[1]['question']\n",
    "    ground_truth = df.iloc[1]['answer']\n",
    "    generated_answer, bleu_score = answer_question(graph, sample_question, ground_truth)\n",
    "    print(f\"Question: {sample_question}\")\n",
    "    print(f\"Generated Answer: {generated_answer}\")\n",
    "    print(f\"Ground Truth: {ground_truth}\")\n",
    "    print(f\"BLEU Score: {bleu_score}\")\n",
    "\n",
    "    graph.close()\n",
    "    print(\"Knowledge graph construction and evaluation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
